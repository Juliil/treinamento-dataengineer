{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3cc7655-9de9-4787-aaa1-5db0a2893a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Dividir os dados em treino (70%) e teste (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Criar o modelo de regressão logística\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho com base na acurácia\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia no conjunto de teste: {acc_test:.2f}\")\n",
    "\n",
    "# Avaliação adicional com validação cruzada (5 folds)\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(f\"Acurácia média com validação cruzada: {cv_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9143f9d6-c2b4-4d77-8bd4-9a5baf84b978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Acurácia no conjunto de teste: 1.00 (100%)\n",
    "Isso significa que, quando o modelo foi avaliado com dados que ele nunca viu durante o treinamento, todas as amostras foram classificadas corretamente.\n",
    "\n",
    "Acurácia média com validaação cruzada: 0.97 (97%)\n",
    "A validação cruzada, ao dividir o dataset em diferentes subconjuntos (folds), fornece uma avaliação mais robusta do desempenho do modelo. Nesse caso, a média de 97% mostra que, em diferentes divisões, o modelo consistentemente teve alta performance.\n",
    "\n",
    "Dataset Simples:\n",
    "O dataset Iris é relativamente simples e possui um número reduzido de amostras e características. Isso pode facilitar a obtenção de acurácias elevadas. Em cenários com dados mais complexos, os resultados podem variar e exigir ajustes adicionais no modelo.\n",
    "\n",
    "Validação Cruzada vs. Conjunto de Teste:\n",
    "\n",
    "O conjunto de teste pode, em alguns casos, apresentar uma divisão que favorece o desempenho (por sorte, por exemplo), levando a uma acurácia perfeita.\n",
    "A validação cruzada, por sua vez, avalia o modelo em diferentes divisões do conjunto de dados, oferecendo uma estimativa mais geral do desempenho.\n",
    "Outras Métricas:\n",
    "Embora a acurácia seja uma boa métrica para datasets equilibrados, é interessante considerar outras métricas (como precisão, recall e F1-score) em problemas onde as classes podem ser desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66ca8d7e-67ea-484a-8d21-323c215b061c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Dividir os dados: 70% para treino e 30% para teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Criar um pipeline que inclui escalonamento e o modelo de regressão logística\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(max_iter=200))\n",
    "])\n",
    "\n",
    "# --- Etapa 1: Treinamento simples e avaliação com o conjunto de teste ---\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia no conjunto de teste (modelo base): {acc_test:.2f}\")\n",
    "\n",
    "# --- Etapa 2: Validação cruzada ---\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(f\"Acurácia média com validação cruzada (modelo base): {cv_scores.mean():.2f}\")\n",
    "\n",
    "# --- Etapa 3: Otimização de hiperparâmetros com GridSearchCV ---\n",
    "# Definir o grid de parâmetros para a regressão logística\n",
    "param_grid = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__penalty': ['l2'],         # Usando penalização L2 (poderia testar l1 com solver adequado)\n",
    "    'model__solver': ['lbfgs']         # Solver adequado para a penalização L2\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV com validação cruzada (5 folds)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Melhores parâmetros encontrados:\", grid_search.best_params_)\n",
    "\n",
    "# Avaliar o modelo otimizado no conjunto de teste\n",
    "y_pred_optimized = grid_search.predict(X_test)\n",
    "acc_test_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"Acurácia no conjunto de teste (modelo otimizado): {acc_test_optimized:.2f}\")\n",
    "\n",
    "# Opcional: Relatório detalhado e matriz de confusão\n",
    "print(\"\\nRelatório de classificação (modelo otimizado):\")\n",
    "print(classification_report(y_test, y_pred_optimized))\n",
    "print(\"Matriz de confusão (modelo otimizado):\")\n",
    "print(confusion_matrix(y_test, y_pred_optimized))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2da08659-f8b7-4cb5-90a8-a48b1af97517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Explicação Detalhada\n",
    "\n",
    "## Treinamento e Avaliação Simples:\n",
    "- **Pipeline:**  \n",
    "  Criamos um pipeline que primeiro padroniza as features usando o `StandardScaler` e, em seguida, aplica a regressão logística.\n",
    "- **Divisão de Dados:**  \n",
    "  Usamos `train_test_split` para separar os dados em treino e teste.\n",
    "- **Avaliação:**  \n",
    "  Após o treinamento, o modelo é avaliado no conjunto de teste e a acurácia é exibida.\n",
    "\n",
    "## Validação Cruzada:\n",
    "- Utilizamos `cross_val_score` para realizar a validação cruzada com 5 folds.\n",
    "- **Folds:**  \n",
    "  Folds são as subdivisões do conjunto de dados utilizadas na validação cruzada. Por exemplo, com 5 folds, o dataset é dividido em 5 partes iguais e, em cada iteração, 4 partes são usadas para treinamento e 1 para validação. Essa técnica ajuda a garantir que o modelo seja avaliado de forma robusta e consistente em diferentes subconjuntos dos dados.\n",
    "- Essa abordagem permite avaliar a consistência do modelo em diferentes divisões do dataset, fornecendo uma média da acurácia.\n",
    "\n",
    "## Otimização de Hiperparâmetros (GridSearchCV):\n",
    "- **Definição de Parâmetros:**  \n",
    "  Montamos um grid com diferentes valores para o parâmetro `C`, que controla a regularização do modelo.\n",
    "- **Busca em Grade:**  \n",
    "  O `GridSearchCV` testa todas as combinações dos parâmetros definidos usando validação cruzada, identificando a melhor configuração para o modelo.\n",
    "- **Solver:**  \n",
    "  O solver é o algoritmo utilizado para otimizar os coeficientes do modelo de regressão logística. No exemplo, usamos o solver `lbfgs`, que é adequado para a penalização L2 e é eficiente para conjuntos de dados pequenos a médios.\n",
    "- **Avaliação do Modelo Otimizado:**  \n",
    "  Após encontrar os melhores parâmetros, reavaliamos o modelo no conjunto de teste e geramos:\n",
    "  - Um **relatório de classificação** que detalha métricas como precisão, recall e F1-score.\n",
    "  - A **matriz de confusão**, que é uma ferramenta para visualizar o desempenho do modelo. Ela mostra a quantidade de classificações corretas e incorretas para cada classe, onde cada linha representa as instâncias reais e cada coluna representa as previsões do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fec6aeda-7399-4290-86f3-cea8baae7f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exemplo de Consumo do Modelo\n",
    "\n",
    "Após treinar e otimizar o modelo, podemos utilizá-lo para fazer previsões em novos dados. Este exemplo demonstra como consumir o modelo para prever a classe de uma nova amostra.\n",
    "\n",
    "## Exemplo de Código\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Exemplo de novo dado com as mesmas features utilizadas no treinamento:\n",
    "# [comprimento_sépala, largura_sépala, comprimento_pétala, largura_pétala]\n",
    "novo_exemplo = np.array([[6.0, 3.0, 4.8, 1.8]])\n",
    "\n",
    "# Realizando a previsão utilizando o modelo otimizado.\n",
    "# Aqui estamos utilizando o objeto `grid_search` que já contém o pipeline treinado e otimizado.\n",
    "predicao = grid_search.predict(novo_exemplo)\n",
    "print(\"Predição para o novo exemplo:\", predicao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45c4cbbe-5948-4d3d-91bd-2e3e1963d366",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulação de um novo dado com as mesmas features utilizadas no treinamento:\n",
    "# [comprimento_sépala, largura_sépala, comprimento_pétala, largura_pétala]\n",
    "novo_exemplo = np.array([[6.0, 3.0, 4.8, 1.8]])\n",
    "\n",
    "# Realizando a previsão utilizando o modelo otimizado.\n",
    "# Neste exemplo, estamos usando o objeto `grid_search` que já contém o pipeline treinado e otimizado.\n",
    "predicao = grid_search.predict(novo_exemplo)\n",
    "print(\"Predição para o novo exemplo:\", predicao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bc8fd87-1062-422a-936c-d2ee6e85144b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Possíveis Cenários de Uso\n",
    "\n",
    "## API REST\n",
    "- O modelo pode ser integrado a uma API REST que receba dados via requisições HTTP e retorne a previsão, possibilitando a integração com aplicações web ou mobile.\n",
    "\n",
    "## Processamento Batch\n",
    "- Em cenários onde é necessário realizar previsões em lote, o modelo pode ser carregado e utilizado para processar grandes volumes de dados periodicamente.\n",
    "\n",
    "## Monitoramento em Tempo Real\n",
    "- O modelo pode ser implementado em sistemas que monitoram dados em tempo real, classificando novas amostras à medida que são recebidas.\n",
    "\n",
    "# Considerações Importantes\n",
    "\n",
    "## Pré-processamento\n",
    "- Certifique-se de que os dados de entrada sejam submetidos ao mesmo pré-processamento (como a padronização com `StandardScaler`) que foi utilizado durante o treinamento.\n",
    "\n",
    "## Persistência do Modelo\n",
    "- Em ambientes de produção, é recomendado salvar o modelo treinado (por exemplo, com `joblib` ou `pickle`) e carregá-lo conforme necessário, evitando retraining a cada nova previsão.\n",
    "\n",
    "## Validação\n",
    "- Teste o modelo com dados reais e monitore sua performance, para garantir que ele continue atendendo aos requisitos do sistema em produção."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "micro-model-exemple",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
