{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5005bb2a-f56a-4f36-b569-3e23e589a2d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import array, col, current_date\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "class Framework:\n",
    "    \"\"\"\n",
    "    Classe de controle para execução dos processos ETL/ELT, com lógica para criação de tabelas Bronze e Silver.\n",
    "    \n",
    "    Camada Bronze:\n",
    "      - Lê os dados da tabela Delta no schema landing.\n",
    "      - Gera a coluna BK_EXTRACAO via MD5.\n",
    "      - Gera a coluna DATA_EXTRACAO com a data atual no formato YYYY-MM-DD.\n",
    "      - Verifica se existe alguma coluna com todos os conteúdos nulos.\n",
    "      - Grava a tabela Bronze no metastore (schema bronze) via APPEND_ALL.\n",
    "    \n",
    "    Camada Silver:\n",
    "      - Lê os dados da tabela Bronze (schema bronze).\n",
    "      - Verifica, no dicionário de metadados (schema dicionarios.dicionario_de_metadados),\n",
    "        se há mapeamento para renomear a tabela na Silver.\n",
    "      - Permite carga via APPEND_ALL ou UPSERT (merge com base na coluna BK_EXTRACAO).\n",
    "    \"\"\"\n",
    "    \n",
    "    class RawFileFormat:\n",
    "        Delta = \"delta\"\n",
    "    \n",
    "    class LoadType:\n",
    "        APPEND_ALL = \"APPEND_ALL\"\n",
    "        UPSERT = \"UPSERT\"\n",
    "    \n",
    "    class SchemaEvolutionMode:\n",
    "        ADD_NEW_COLUMNS = \"ADD_NEW_COLUMNS\"\n",
    "    \n",
    "    @classmethod\n",
    "    def generate_bronze_table_full_name(cls, schema_name, table_name):\n",
    "        \"\"\"\n",
    "        Gera o nome completo da tabela Bronze no metastore, no formato schema.table.\n",
    "        \"\"\"\n",
    "        return f\"{schema_name}.{table_name}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def write_delta_table(cls, df, schema_name, table_full_name, load_type, key_columns, partition_columns, schema_evolution_mode):\n",
    "        \"\"\"\n",
    "        Escrita da Delta Table no metastore (usado na camada Bronze).\n",
    "        Utiliza saveAsTable para criar ou acrescentar dados na tabela.\n",
    "        \"\"\"\n",
    "        spark.sql(f\"CREATE DATABASE IF NOT EXISTS {schema_name}\")\n",
    "        df.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"append\").saveAsTable(table_full_name)\n",
    "        print(\"Escrita na camada Bronze realizada com sucesso.\")\n",
    "\n",
    "    def execute_etl(self, \n",
    "                    schema_name: str,\n",
    "                    source_table: str,\n",
    "                    landing_table: str,\n",
    "                    target_table: str,\n",
    "                    bk_columns_keys: list,\n",
    "                    partition: str = \"\"):\n",
    "        \"\"\"\n",
    "        Executa o fluxo ETL para a camada Bronze.\n",
    "        \n",
    "        :param schema_name: Schema de destino (ex.: \"bronze\").\n",
    "        :param source_table: Nome da tabela fonte (ex.: \"sales_oracle_system\") – usado para identificar o processo.\n",
    "        :param landing_table: Nome da tabela Delta no schema landing (ex.: \"landing.sales_oracle_system\").\n",
    "        :param target_table: Nome da tabela destino (ex.: \"sales_oracle_system\").\n",
    "        :param bk_columns_keys: Lista de colunas para gerar a chave de extração.\n",
    "        :param partition: Coluna(s) de particionamento (opcional).\n",
    "        \"\"\"\n",
    "        # Leitura direta da tabela Delta na camada landing\n",
    "        df = spark.table(landing_table)\n",
    "        \n",
    "        # Geração da coluna BK_EXTRACAO (hash MD5 da concatenação das colunas informadas)\n",
    "        df = df.withColumn(\n",
    "            \"BK_EXTRACAO\", \n",
    "            F.md5(F.concat_ws('_', array(*[col(c) for c in bk_columns_keys])))\n",
    "        )\n",
    "        \n",
    "        # Geração da coluna DATA_EXTRACAO com a data atual no formato YYYY-MM-DD\n",
    "        df = df.withColumn(\"DATA_EXTRACAO\", current_date())\n",
    "        \n",
    "        # Verificação de colunas com todos os conteúdos nulos\n",
    "        null_columns = [c for c in df.columns if df.filter(col(c).isNotNull()).count() == 0]\n",
    "        if null_columns:\n",
    "            print(f\"Colunas com todos os conteúdos nulos: {null_columns}\")\n",
    "        \n",
    "        key_columns = [\"BK_EXTRACAO\"]\n",
    "        \n",
    "        # Gera o nome completo da tabela Bronze (ex.: bronze.sales_oracle_system)\n",
    "        table_full_name = Framework.generate_bronze_table_full_name(schema_name, target_table)\n",
    "        \n",
    "        # Escrita da Delta Table no schema Bronze\n",
    "        Framework.write_delta_table(\n",
    "            df=df,\n",
    "            schema_name=schema_name,\n",
    "            table_full_name=table_full_name,\n",
    "            load_type=Framework.LoadType.APPEND_ALL,\n",
    "            key_columns=key_columns,\n",
    "            partition_columns=partition,\n",
    "            schema_evolution_mode=Framework.SchemaEvolutionMode.ADD_NEW_COLUMNS,\n",
    "        )\n",
    "    \n",
    "    def execute_silver(self, \n",
    "                       silver_schema: str,\n",
    "                       bronze_table: str,\n",
    "                       target_table: str,\n",
    "                       load_type: str,\n",
    "                       partition: str = \"\"):\n",
    "        \"\"\"\n",
    "        Executa o fluxo para a camada Silver.\n",
    "        \n",
    "        Lê os dados da tabela Bronze (do schema bronze) e verifica, no dicionário de metadados,\n",
    "        se existe um registro onde o campo 'nome_tabela_origem' seja igual ao nome da tabela Bronze.\n",
    "        Se existir, o nome da tabela Silver passará a ser o valor do campo 'nome_tabela_transformada';\n",
    "        caso contrário, utiliza o valor informado em target_table.\n",
    "        \n",
    "        Permite dois modos de carga:\n",
    "          - APPEND_ALL: Acrescenta os dados;\n",
    "          - UPSERT: Realiza merge (update/insert) usando a coluna BK_EXTRACAO.\n",
    "        \n",
    "        :param silver_schema: Schema de destino para a Silver (ex.: \"silver\").\n",
    "        :param bronze_table: Nome da tabela Bronze (ex.: \"sales_oracle_system\") – presente no schema bronze.\n",
    "        :param target_table: Nome sugerido para a tabela Silver; poderá ser alterado conforme o dicionário.\n",
    "        :param load_type: Modo de carga: Framework.LoadType.APPEND_ALL ou Framework.LoadType.UPSERT.\n",
    "        :param partition: Coluna(s) de particionamento (opcional).\n",
    "        \"\"\"\n",
    "        # Leitura dos dados da camada Bronze (assumindo que ela esteja no schema \"bronze\")\n",
    "        bronze_full_name = f\"bronze.{bronze_table}\"\n",
    "        df = spark.table(bronze_full_name)\n",
    "        \n",
    "        # Verifica o dicionário de metadados para mapear o nome da tabela Silver\n",
    "        try:\n",
    "            meta_df = spark.table(\"dicionarios.dicionario_de_metadados\")\n",
    "            meta_filtered = meta_df.filter(F.col(\"nome_tabela_origem\") == bronze_table).limit(1).collect()\n",
    "            if meta_filtered and len(meta_filtered) > 0:\n",
    "                silver_table_name = meta_filtered[0][\"nome_tabela_transformada\"]\n",
    "                print(f\"Mapeamento encontrado no dicionário: {bronze_table} -> {silver_table_name}\")\n",
    "            else:\n",
    "                silver_table_name = target_table\n",
    "                print(\"Nenhum mapeamento encontrado no dicionário; usando target_table informado.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao acessar dicionário de metadados: {e}\")\n",
    "            silver_table_name = target_table\n",
    "        \n",
    "        # Define o nome completo da tabela Silver\n",
    "        full_silver_table_name = f\"{silver_schema}.{silver_table_name}\"\n",
    "        \n",
    "        # Cria o database Silver se não existir\n",
    "        spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_schema}\")\n",
    "        \n",
    "        if load_type == Framework.LoadType.APPEND_ALL:\n",
    "            # Escrita simples via append\n",
    "            df.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\"append\").saveAsTable(full_silver_table_name)\n",
    "            print(\"Escrita na camada Silver realizada com sucesso (APPEND_ALL).\")\n",
    "        elif load_type == Framework.LoadType.UPSERT:\n",
    "            # Lógica de UPSERT utilizando merge baseado em BK_EXTRACAO\n",
    "            try:\n",
    "                # Tenta obter a DeltaTable já existente\n",
    "                silver_delta = DeltaTable.forName(spark, full_silver_table_name)\n",
    "                merge_condition = \"source.BK_EXTRACAO = target.BK_EXTRACAO\"\n",
    "                silver_delta.alias(\"target\").merge(\n",
    "                    source=df.alias(\"source\"),\n",
    "                    condition=merge_condition\n",
    "                ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "                print(\"Merge UPSERT na camada Silver realizado com sucesso.\")\n",
    "            except Exception as e:\n",
    "                # Caso a tabela não exista ou não seja Delta, cria-a\n",
    "                print(f\"Tabela Silver não existe ou não é Delta: {e}. Criando tabela como Delta...\")\n",
    "                df.write.format(\"delta\").mode(\"append\").saveAsTable(full_silver_table_name)\n",
    "                print(\"Tabela Silver criada e dados inseridos (UPSERT via append).\")\n",
    "        else:\n",
    "            raise NotImplementedError(\"Load type não implementado para Silver.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "classe_de_controle",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
